---
layout: article_home
<!-- title: Knowledge Representation for Hybrid and Compositional AI (KRHCAI 2021 Workshop)
subtitle: To be held jointly with the  KR2021 Conference -->
title:  KRHCAI 2021
subtitle: Workshop on Knowledge Representation for Hybrid & Compositional AI
subtitle2: at KR2021
subtitle3: 3rd November 2021, UTC 08:30 - 15:00

header:
  theme: dark
  background: '#123'
article_header:
  type: overlay
  theme: dark
  background_color: '#123'
  background_image: false
key: page-index
---

<!-- Just say something about yourself. :+1:

{% highlight javascript %}
(() => console.log('hello, world!'))();
{% endhighlight %} -->

<div style="padding-top: 50px">
    <div>
        AI research over the past few decades has highlighted the strengths and weaknesses of both symbolic and machine learning approaches to AI, with some weaknesses in one being strengths in the other. Much is also known about the fragmentation of the field along these two approaches. However, recent discussions in AI have highlighted the need to integrate both symbolic and sub-symbolic methods, in a hybrid approach to AI, to create novel techniques that leverage both reasoning and learning. 

        This workshop seeks to contribute to this discussion by exploring the following: 
        <ul>
            <li><i>a systems approach to AI,</i></li>
            <li><i>the use of composable AI components,</i></li>
            <li><i>leveraging the best of both symbolic and sub-symbolic techniques in hybrid reasoning and learning architectures.</i></li>
        </ul>
        
        To achieve the above, there is the need to explore novel knowledge representation techniques that allow 
        the seamless flow of computations between symbolic and sub-symbolic AI components.  
        There is also the need to develop new datasets that evaluate the capabilities highlighted above, 
        especially focusing on problems that cannot be solved by end-to-end differentiable neural network 
        architectures or purely symbolic reasoning methods alone. 

    </div>
    <br/>
    <div style="color:rgb(241, 57, 57)">Date: <b>3rd November 2021</b>, Time: <b>UTC 08:30 - 15:00</b></div>
    <br/>

    <a name="register"></a>
    <h2>Register</h2>
    Registration is free but mandatory for all who want to attend the workshop.
    <a href="https://kr2021.kbsg.rwth-aachen.de/page/registration" target="_blank">Click this link to register</a> on the KR2020 website.   
    <div style="clear:both;"></div>

    



    <!-- <a name="speakers"></a>
    <h2>Invited Speakers and Panel</h2>
    <br/>
    <div>
        <div class="image-cropper" style="float:left;  margin-right: 20px">
            <img src="assets/images/speakers/ag.png" class="rounded" />
        </div>
        <div style="float:left;">
            <div class="name">Dr. Alexander Gray</div>
            <div class="affil">IBM</div>
            
        </div>
        <div style="clear:both;"></div>
        <h4 class="abstract-title">Logical Neural Networks</h4>
        <div class="abstract">
            Recently there has been renewed interest in the long-standing goal of somehow unifying the capabilities of both statistical 
            AI (learning and prediction) and symbolic AI (knowledge representation and reasoning).  We introduce Logical Neural Networks, 
            a new neuro-symbolic framework which identifies and leverages a 1-to-1 correspondence between an artificial neuron and a 
            logic gate in a weighted form of real-valued logic.  With a few key modifications of the standard modern neural network, 
            we construct a model which performs the equivalent of logical inference rules such as modus ponens within the message-passing 
            paradigm of neural networks, and utilizes a new form of loss, contradiction loss, which maximizes logical consistency in the 
            face of imperfect and inconsistent knowledge.  The result differs significantly from other neuro-symbolic ideas in that 1) the 
            model is fully disentangled and understandable since every neuron has a meaning, 2) the model can perform both classical 
            logical deduction and its real-valued generalization (which allows for the representation and propagation of uncertainty) 
            exactly, as special cases, as opposed to approximately as in nearly all other approaches, and 3) the model is compositional 
            and modular, allowing for fully reusable knowledge across talks.  The framework has already enabled state-of-the-art results 
            in several problems, including question answering.
        </div>
        <div class="bio">
            Alexander Gray serves as VP of Foundations of AI at IBM, and currently leads a global research program in Neuro-Symbolic AI at IBM.  
            He received AB degrees in Applied Mathematics and Computer Science from UC Berkeley and a PhD in Computer Science from Carnegie Mellon University.  
            Before IBM he worked at NASA, served as a tenured Associate Professor at the Georgia Institute of Technology, 
            and co-founded and sold an AI startup in Silicon Valley.  His work on machine learning, statistics, and algorithms for massive datasets, 
            predating the movement of "big data" in industry, has been honored with a number of research honors including multiple best paper awards, 
            the NSF CAREER Award, selection as a National Academy of Sciences Kavli Scholar, and service as a member of the 
            2010 National Academy of Sciences Committee on the Analysis of Massive Data.  His current interests generally revolve around the 
            injection of non-mainstream ideas into ML/AI to attempt to break through long-standing bottlenecks of the field. 
        </div>
    </div>

    <div style="margin-top:50px">
        <div class="image-cropper" style="float:left;  margin-right: 20px">
            <img src="assets/images/speakers/ar.png" class="rounded" />
        </div>
        <div style="float:left;">
            <div class="name">Prof. Alessandra Russo</div>
            <div class="affil">Imperial College London</div>
            
        </div>
        <div style="clear:both;"></div>
        
        <h4 class="abstract-title">Symbolic Machine Learning and its role in Neuro-symbolic AI</h4>
        <div class="abstract">
            Learning interpretable models from data is one of the main challenges of AI. Over the last two decades there has been growing 
            interest in Symbolic Machine Learning, a field of Machine Learning that aims to develop algorithms and systems for learning 
            models that explain data within the context of some given background knowledge. In contrast to statistical learning methods, 
            models learned by Symbolic Machine Learning are interpretable: they can be translated into natural language and understood by humans. 
            In the first part of this talk we present Learning from Answer Sets (LAS), a state-of-the-art Symbolic Machine Learning approach 
            capable of learning different classes of models, including those which are non-monotonic, nondeterministic and/or preference-based. 
            We show how the advanced features of the LAS framework have made it possible to solve a variety of real-world problems in a manner 
            that is data efficient, scalable and robust to noise. LAS can be combined with statistical learning methods to realise neuro-symbolic 
            solutions that perform both fast, “low-level” prediction from unstructured data, and “high-level” logical and interpretable learning. 
            In the second part of this talk we will present two such neuro-symbolic solutions for respectively solving image classification 
            problems in the presence of distribution shifts, and discovering sub-goal structures for reinforcement learning agents.

        </div> 
        <div class="bio">
            Alessandra Russo is Professor of Applied Computational Logic at the Department of Computing, Imperial College London, 
            where she leads the Structured and Probabilistic Intelligent Knowledge Engineering (SPIKE) group. She has strong expertise 
            in Computational Logic, Knowledge Representation, Symbolic Machine Learning, and Probabilistic inference. 
            She has pioneered new Symbolic Machine Learning algorithms, which are among the state-of-the-art learning systems, 
            and gained an established track record on the application of these systems to failure prediction, policy and preference 
            learning, classification, and recommendation learning. She has been Editor-in-chief of IET Software, 
            Editor of ACM Computing Surveys and is currently Associate Editor of the TPLP journal for the area of Logic and Machine Learning.
        </div>
    </div>

    <div style="margin-top:50px">
        <div class="image-cropper" style="float:left;  margin-right: 20px">
            <img src="assets/images/speakers/pm.png" class="rounded" />
        </div>
        <div style="float:left;">
            <div class="name">Dr. Pasquale Minervini</div>
            <div class="affil">University College London (UCL)</div>
            
        </div>
        <div style="clear:both;"></div>
        
        <h4 class="abstract-title">From Complex Query Answering to Neural Theorem Proving</h4>
        <div class="abstract">
            Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. 
            However, it is still not clear how to use these models for answering more complex queries that arise in a 
            number of domains, such as queries using logical conjunctions, disjunctions, and existential quantifiers, 
            while accounting for missing edges. In this work, we propose a framework for efficiently answering complex 
            queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, 
            where the truth value of each atom is computed by a pre-trained neural link predictor; we then analyse two 
            solutions to the optimisation problem, including gradient-based and combinatorial search. The proposed 
            approach produces more accurate results than state-of-the-art methods --- black-box neural models trained on 
            millions of generated queries --- without the need for training on a large and diverse set of complex queries. 
            Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in 
            Hits@3 across different Knowledge Graphs containing factual information. 
            Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate 
            solutions identified for each of the complex query atoms. This work was presented at ICLR 2021, 
            where it was awarded an Outstanding Paper Award. We then will discuss how can we extend this framework to 
            develop end-to-end differentiable reasoning systems, that can learn symbolic rules via back-propagation, 
            use them for tasks that require deductive reasoning, and use the resulting proof paths for producing explanations 
            to its users.
        </div>
        <div class="bio">
            Pasquale Minervini is a Senior Research Fellow at University College London (UCL). 
            He received a PhD in Computer Science from University of Bari, Italy, with a thesis on relational learning. 
            After his PhD, he worked as a postdoc researcher at the University of Bari, and at the INSIGHT Centre for 
            Data Analytics (INSIGHT), where he worked in close collaboration with researchers and engineers from INSIGHT 
            and Fujitsu Ireland Research and Innovation. Pasquale published peer-reviewed papers in top-tier AI conferences, 
            receiving three best paper awards (including an Outstanding Paper Award at ICLR 2021), participated in the 
            organisation of tutorials on Explainable AI and relational learning (three for AAAI, one for ECML, and others), 
            and was a guest lecturer at UCL and at the Summer School on Statistical Relational Artificial Intelligence. 
            He is the main inventor of a patent application assigned to Fujitsu Ltd, and he was recently awarded a seven-figures 
            H2020 research grant involving applications of relational learning to cancer research, and several other research 
            grants from industry. For more information about him, see <a href="http://www.neuralnoise.com" target="_blank">http://www.neuralnoise.com</a>
        </div>
    </div>    

    <div style="margin-top:50px">
        <div class="image-cropper" style="float:left;  margin-right: 20px">
            <img src="assets/images/speakers/ab.png" class="rounded" />
        </div>
        <div style="float:left;">
            <div class="name">Dr. Antoine Bosselut</div>
            <div class="affil">École Polytechnique Fédéral de Lausanne (EPFL)</div>
            
        </div>
        <div style="clear:both;"></div>
        
        <h4 class="abstract-title">Symbolic Scaffolds for Neural Commonsense Representation and Reasoning</h4>
        <div class="abstract">
            Situations described using natural language are richer than what humans explicitly communicate. 
            For example, the sentence "She pumped her fist" connotes many potential auspicious causes. 
            For machines to understand natural language, they must be able to make commonsense inferences about explicitly stated information. 
            However, current NLP systems lack the ability to ground the situations they encounter to relevant world knowledge. 
            Moreover, they struggle to reason over available facts to robustly generalize to future unseen events. 
            In this talk, I will describe efforts at transforming modern language models into robust commonsense knowledge models by 
            leveraging implicitly encoded knowledge representations. 
            Then, I will discuss work in designing robust reasoning systems that use knowledge graphs as a structural scaffold for 
            aggregating information across relevant commonsense inferences.
        </div> 
        <div class="bio">
            Antoine Bosselut is an assistant professor in the School of Computer and Communication Sciences at the École Polytechnique Fédéral de Lausanne (EPFL).
            Previously, he was a postdoctoral scholar at Stanford University and a Young Investigator at the Allen Institute for AI (AI2). 
            He completed his PhD at the University of Washington in 2020. 
            He was recently named as one of the Forbes 30 under 30 list for Science and Healthcare. 
            His research is on building knowledge-aware NLP systems, specializing in commonsense representation and reasoning.
        </div>
    </div>

    

    <div style="margin-top:50px">
        <div class="image-cropper" style="float:left;  margin-right: 20px">
            <img src="assets/images/speakers/jl.png" class="rounded" />
        </div>
        <div style="float:left;">
            <div class="name">Dr. Jaehun Lee</div>
            <span class="affil">Samsung Research</div>  
        </div>
        <div style="clear:both;"></div>
        <div class="bio_panel">
            Dr. Jaehun Lee is currently a researcher at Samsung Research, working in the space of large knowledge graph construction, 
            reasoning and its applications for mobile phones and consumer electronics. The applications include search and recommendations 
            for virtual assistants, diagnosis and treatment recommendations for call center operation, data curation to unify heterogeneous data. 
            In the past, he has worked on various research topics such as knowledge representation, ontology reasoning, and machine learning.
        </div>
    </div>
    

    <div style="margin-top:50px">
        <div class="image-cropper" style="float:left;  margin-right: 20px">
            <img src="assets/images/speakers/vb.png" class="rounded" />
        </div>
        <div style="float:left;">
            <div class="name">Dr. Vaishak Belle</div>
            <div class="affil">University of Edinburgh</div>     
        </div>
        <div style="clear:both;"></div>    
        <div class="bio_panel">
            Dr Vaishak Belle is a Chancellor’s Fellow and Faculty at the School of Informatics, University of Edinburgh, 
            an Alan Turing Institute Faculty Fellow, a Royal Society University Research Fellow, and a member of the 
            RSE (Royal Society of Edinburgh) Young Academy of Scotland. At the University of Edinburgh, 
            he directs a research lab on artificial intelligence, specialising in the unification of logic and 
            machine learning, with a recent emphasis on explainability and ethics. He has given research seminars 
            at numerous academic institutions, tutorials at AI conferences, and talks at venues such as Ars Electronica 
            and the Samsung AI Forum. He has co-authored over 50 scientific articles on AI, at venues such as IJCAI, 
            UAI, AAAI, MLJ, AIJ, JAIR, AAMAS, and along with his co-authors, he has won the Microsoft best paper award 
            at UAI, the Machine learning journal best student paper award at ECML-PKDD, and the Machine learning journal 
            best student paper award at ILP. In 2014, he received a silver medal by the Kurt Goedel Society. 
            Recently, he has consulted with major banks on explainable AI and its impact in financial institutions.
        </div>
    </div> -->

    <a name="program"></a>
    <br/>
    <h2>Program</h2>
    <div>
        <table class="styled-table">
            <thead>
                <tr>
                    <th>Time (UTC)</th>
                    <th>Item</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>08:30 - 08:45</td> 
                    <td>Welcome & Introduction</td>
                </tr>
                <tr>
                    <td>08:45 - 09:45</td> 
                    <td>
                        Invited Talk by <span class='speaker'>Alexander Gray </span>                       
                        <div class="title">Logical Neural Networks</div>
                    </td>
                </tr>
                <tr>
                    <td>09:45 - 09:55</td> 
                    <td>
                        Lightning Talk by <span class='speaker'>Kwabena Nuamah</span>
                        <div class="title">Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning</div>
                    </td>
                </tr>
                <tr>
                    <td>09:55 - 10:55</td> 
                    <td>
                        Invited Talk by  <span class='speaker'>Antoine Bosselut</span>
                        <div class="title">Symbolic Scaffolds for Neural Commonsense Representation and Reasoning </div>
                    </td>
                </tr>
                <tr class="active-row"><td >10:55 - 11:00</td> <td>Coffee Break</td></tr>
                <tr>
                    <td>11:00 - 11:10</td> 
                    <td>Lightning Talk by <span class='speaker'>Chloé Mercier</span>
                        <div class="title">Ontology as Neuronal-Space Manifold: Towards Symbolic and Numerical Artificial Embedding </div>
                    </td>
                </tr>
                <tr>
                    <td>11:10 - 12:10</td> 
                    <td>Invited Talk by <span class='speaker'>Alessandra Russo</span>
                        <div class="title">Symbolic Machine Learning and its role in Neuro-symbolic AI </div>
                    </td>
                </tr>
                <tr class="active-row"><td >12:10 - 12:50</td> <td>Break </td></tr>
                <tr>
                    <td>12:50 - 13:00</td> 
                    <td>
                        Lightning Talk by <span class='speaker'>Patrick Kage</span>
                        <div class="title">Class Introspection: A Novel Technique for Detecting Unlabeled Subclasses by Leveraging Classifier Explainability Methods </div>
                    </td>
                </tr>
                <tr>
                    <td>13:00 - 14:00</td> 
                    <td>
                        Invited Talk by <span class='speaker'>Pasquale Minervini</span>
                        <div class="title">From Complex Query Answering to Neural Theorem Proving</div>
                    </td>
                </tr>
                <tr>
                    <td>14:00 - 15:00</td> 
                    <td>
                        <span class='speaker'>Panel Discussion</span>
                        <div class="title">Alexander Gray, Antoine Bosselut, Alessandra Russo, Pasquale Minervini, Vaishak Belle, Jaehun Lee </div>
                    </td>
                </tr>
                <tr>
                    <td>15:00 - 15:20</td> 
                    <td>
                        General Discussion & Wrap Up
                    </td>
                </tr>
            </tbody>
        </table>
    </div>
    

    <div style="margin-top:30px;">
        More about our <a href="/speakers">invited speakers and panel here </a>.
    </div>


    

    <a name="organizers"></a>
    <br/>
    <h2>Program Committee</h2>
    <h3>Organizers</h3>
    <div>
        <div class="org">
            <div class="image-cropper-small" style="float:left;  margin-right: 20px">
                <img src="assets/images/speakers/kn.png" class="rounded" />
            </div>
            <div style="float:left;">
                <div class="name-org">Dr. Kwabena Nuamah</div>
                <div class="affil-org">University of Edinburgh</div>     
            </div>
        </div>


        <div class="org">
            <div class="image-cropper-small" style="float:left;  margin-right: 20px">
                <img src="assets/images/speakers/et.png" class="rounded" />
            </div>
            <div style="float:left;">
                <div class="name-org">Dr. Efi Tsamoura</div>
                <div class="affil-org">Samsung AI Research</div>     
            </div>
        </div>

        <div class="org">
            <div class="image-cropper-small" style="float:left;  margin-right: 20px">
                <img src="assets/images/speakers/pk.png" class="rounded" />
            </div>
            <div style="float:left;">
                <div class="name-org">Dr. Pavan Kapanipathi</div>
                <div class="affil-org">IBM Research</div>     
            </div>
        </div>

        <div class="org">
            <div class="image-cropper-small" style="float:left;  margin-right: 20px">
                <img src="assets/images/speakers/jp.png" class="rounded" />
            </div>
            <div style="float:left;">
                <div class="name-org">Dr. Jeff Z. Pan</div>
                <div class="affil-org">University of Edinburgh</div>     
            </div>
        </div>

        <div style="clear:both;"></div>
        
        <h3> Program Committee Members</h3>
        <div>
        <ul>
            <li>Massimiliano Patacchiola (University of Cambridge)</li>
            <li>Paolo Pareti (University of Winchester)</li>
            <li>Pavlos Andreadis (University of Edinburgh)</li>
            <!-- <li>Ibrahim Abdelaziz (IBM Research)</li> -->
        </ul>
    </div>
    </div>

    
    
    
    
</div>